{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EOD data extraction ETL process\n",
    "\n",
    "The following ETL process will extract data from [eodhistoricaldata.com](https://eodhistoricaldata.com/) API. This API offers historical and end-of-day financial market data for various asset classes, including stocks, indices, options, futures, currencies, and cryptocurrencies. The data provided may include historical prices, trading volumes, fundamental financial data, splits, dividends, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from io import StringIO\n",
    "from typing import Optional\n",
    "import requests\n",
    "import awswrangler as wr\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "from utilities import init_session, sanitize_dates, format_date, url, RemoteDataError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating S3 bucket\n",
    "This step assumes that you have configured your AWS CLI locally, if this is not the case you can follow this link in order to configure your [AWS Command Line Interface](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-welcome.html).\n",
    "\n",
    "You can run the cell above or you can also execute the following line in your command line `aws s3api create-bucket --bucket eod-data-test-bucket --region us-east-2 --create-bucket-configuration LocationConstraint=us-east-2`, it will create a new bucket in your S3 storage named `eod-data-test-bucket` or any other name you prefer, just please follow this link that will guide you on the naming rules for buckets [Bucket naming rules](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3api create-bucket --bucket eod-data-test-bucket --region us-east-2 --create-bucket-configuration LocationConstraint=us-east-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting local variables\n",
    "\n",
    "In this step is necessary that you register for a free account on [eodhistoricaldata.com](https://eodhistoricaldata.com/), once registered go to the settings page to get access token. For free accounts only 20 API calls are allowed  per days, which will be more than enough for this ETL process.\n",
    "\n",
    "Once your token is set is recommended to store tokens and access keys in your environment variables, in the case you are working in a Windows or a Linux environment. Then you can use the `os` python module in order to call those credentials to your script.\n",
    "\n",
    "I heve previously stored my credentials as environment variables in Windows by running `setx [VARIABLE_NAME] \"VARIABLE_VALUE\"` in the Command Prompt or follow this [link](https://geekflare.com/system-environment-variables-in-windows/) for guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting variables\n",
    "token = os.getenv('EOD_API_TOKEN')\n",
    "aws_key = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "aws_secret = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "#This API key is used for demo purposes\n",
    "EOD_HISTORICAL_DATA_API_KEY_DEFAULT = \"OeAFFmMliFG5orCUuwAKQ8l4WWFQ67YX\"\n",
    "EOD_HISTORICAL_DATA_API_URL = \"https://eodhistoricaldata.com/api\"\n",
    "#This is the bucket name that was created in your AWS account\n",
    "bucket = 'eod-datalake'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper functions\n",
    "\n",
    "These functions will help to get data from the EOD API and once the data is pulled from the API, we will store it in S3 bucket and in Google Sheets for data visualization purposes.\n",
    " \n",
    "There are some endpoints to get data from EOD, [fundamentals](https://eodhd.com/financial-apis/stock-etfs-fundamental-data-feeds/), [real-time](https://eodhd.com/financial-apis/live-realtime-stocks-api/), [end of day](https://eodhd.com/financial-apis/api-for-historical-data-and-volumes/), [intraday](https://eodhd.com/financial-apis/intraday-historical-data-api/) and [Web Socket Connection](https://eodhd.com/financial-apis/new-real-time-data-api-websockets/). Some of them are available for the free tier, and we will use for this demo the `eod` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eod_data(symbol:str,\n",
    "                 exchange:str,\n",
    "                 endpoint:str,\n",
    "                 start:Optional[str] = None,\n",
    "                 end:Optional[str] = None,\n",
    "                 api_key=token,\n",
    "                 session=None):\n",
    "    \"\"\"\n",
    "    Returns EOD (end of day data) for a given symbol\n",
    "    \"\"\"\n",
    "    symbol_exchange = symbol + \".\" + exchange\n",
    "    session = init_session(session)\n",
    "    start, end = sanitize_dates(start, end)\n",
    "    endpoint = f\"/{endpoint}/{symbol_exchange}\"\n",
    "    url = EOD_HISTORICAL_DATA_API_URL + endpoint\n",
    "    params = {\n",
    "        \"api_token\": api_key,\n",
    "        \"from\": format_date(start),\n",
    "        \"to\": format_date(end)\n",
    "    }\n",
    "    \n",
    "    r = session.get(url, params=params)\n",
    "    \n",
    "    if r.status_code == requests.codes.ok:\n",
    "        df = pd.read_csv(StringIO(r.text), \n",
    "                         skipfooter=1,\n",
    "                         parse_dates=[0], \n",
    "                         index_col=0)\n",
    "        return df\n",
    "    \n",
    "    else:\n",
    "        params[\"api_token\"] = \"YOUR_HIDDEN_API\"\n",
    "        raise RemoteDataError(r.status_code, r.reason, url(url, params))\n",
    "        \n",
    "def get_fundamental_data(symbol: str,\n",
    "                         exchange: str,\n",
    "                         endpoint: str,\n",
    "                         api_key=token,\n",
    "                         session=None):\n",
    "    \"\"\"\n",
    "    Returns EOD (end of day data) for a given symbol\n",
    "    \"\"\"\n",
    "    symbol_exchange = symbol + \".\" + exchange\n",
    "    session = init_session(session)\n",
    "    endpoint = f\"/{endpoint}/{symbol_exchange}\"\n",
    "    url = EOD_HISTORICAL_DATA_API_URL + endpoint\n",
    "    params = {\n",
    "        \"api_token\": api_key\n",
    "    }\n",
    "    \n",
    "    r = session.get(url, params=params)\n",
    "    \n",
    "    if r.status_code == requests.codes.ok:\n",
    "        #df = pd.read_csv(StringIO(r.text), skipfooter=1,\n",
    "        #                 parse_dates=[0], index_col=0)\n",
    "        print(r.text)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return r.text\n",
    "\n",
    "def write_data_to_bucket(file_name:str, mode:str):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    mode(str): Available write modes are 'append', 'overwrite' and 'overwrite_partitions'\n",
    "    \"\"\"\n",
    "\n",
    "    path = f\"s3://{bucket}/raw-data/{file_name}\"\n",
    "    #Sending dataframe of corresponding ticker to bucket\n",
    "    wr.s3.to_csv(\n",
    "        df=df,\n",
    "        path=path,\n",
    "        index=True,\n",
    "        dataset=True,\n",
    "        mode=mode\n",
    "    )\n",
    "\n",
    "def read_csv_from_bucket(folder_name:str) -> pd.DataFrame:\n",
    "\n",
    "    df = wr.s3.read_csv(path = f\"s3://{bucket}/raw-data/{folder_name}/\",\n",
    "                        path_suffix = \".csv\"\n",
    ")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = ['AAPL','AMZN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 250 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix\\AppData\\Local\\Temp\\ipykernel_7552\\3566820975.py:25: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(StringIO(r.text),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adjusted_close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-08-08</th>\n",
       "      <td>166.37</td>\n",
       "      <td>167.81</td>\n",
       "      <td>164.20</td>\n",
       "      <td>164.87</td>\n",
       "      <td>164.1190</td>\n",
       "      <td>60276900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-09</th>\n",
       "      <td>164.02</td>\n",
       "      <td>165.82</td>\n",
       "      <td>163.25</td>\n",
       "      <td>164.92</td>\n",
       "      <td>164.1688</td>\n",
       "      <td>63135500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10</th>\n",
       "      <td>167.68</td>\n",
       "      <td>169.34</td>\n",
       "      <td>166.90</td>\n",
       "      <td>169.24</td>\n",
       "      <td>168.4691</td>\n",
       "      <td>70170500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-11</th>\n",
       "      <td>170.06</td>\n",
       "      <td>170.99</td>\n",
       "      <td>168.19</td>\n",
       "      <td>168.49</td>\n",
       "      <td>167.7225</td>\n",
       "      <td>57149200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-12</th>\n",
       "      <td>169.82</td>\n",
       "      <td>172.17</td>\n",
       "      <td>169.40</td>\n",
       "      <td>172.10</td>\n",
       "      <td>171.3161</td>\n",
       "      <td>68039400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close  Adjusted_close    Volume\n",
       "Date                                                                \n",
       "2022-08-08  166.37  167.81  164.20  164.87        164.1190  60276900\n",
       "2022-08-09  164.02  165.82  163.25  164.92        164.1688  63135500\n",
       "2022-08-10  167.68  169.34  166.90  169.24        168.4691  70170500\n",
       "2022-08-11  170.06  170.99  168.19  168.49        167.7225  57149200\n",
       "2022-08-12  169.82  172.17  169.40  172.10        171.3161  68039400"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stores in a dataframe data for a single ticker\n",
    "df1 = get_eod_data(symbols[0], \"US\", \"eod\")\n",
    "print(f\"This dataset has {df1.shape[0]} rows\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 250 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix\\AppData\\Local\\Temp\\ipykernel_7552\\3566820975.py:25: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(StringIO(r.text),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adjusted_close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-08-08</th>\n",
       "      <td>142.050</td>\n",
       "      <td>144.2300</td>\n",
       "      <td>138.2900</td>\n",
       "      <td>139.41</td>\n",
       "      <td>139.41</td>\n",
       "      <td>52303480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-09</th>\n",
       "      <td>138.052</td>\n",
       "      <td>138.9523</td>\n",
       "      <td>136.2100</td>\n",
       "      <td>137.83</td>\n",
       "      <td>137.83</td>\n",
       "      <td>40434719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-10</th>\n",
       "      <td>142.900</td>\n",
       "      <td>144.6000</td>\n",
       "      <td>141.0100</td>\n",
       "      <td>142.69</td>\n",
       "      <td>142.69</td>\n",
       "      <td>54773820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-11</th>\n",
       "      <td>143.860</td>\n",
       "      <td>144.4900</td>\n",
       "      <td>139.7600</td>\n",
       "      <td>140.64</td>\n",
       "      <td>140.64</td>\n",
       "      <td>44867340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-12</th>\n",
       "      <td>142.050</td>\n",
       "      <td>143.5700</td>\n",
       "      <td>140.1201</td>\n",
       "      <td>143.55</td>\n",
       "      <td>143.55</td>\n",
       "      <td>47643480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open      High       Low   Close  Adjusted_close    Volume\n",
       "Date                                                                     \n",
       "2022-08-08  142.050  144.2300  138.2900  139.41          139.41  52303480\n",
       "2022-08-09  138.052  138.9523  136.2100  137.83          137.83  40434719\n",
       "2022-08-10  142.900  144.6000  141.0100  142.69          142.69  54773820\n",
       "2022-08-11  143.860  144.4900  139.7600  140.64          140.64  44867340\n",
       "2022-08-12  142.050  143.5700  140.1201  143.55          143.55  47643480"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stores in a dataframe data for a single ticker\n",
    "df2 = get_eod_data(symbols[1], \"US\", \"eod\")\n",
    "print(f\"This dataset has {df2.shape[0]} rows\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dataframes\n",
    "df_list = [df1, df2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames saved as CSV files in the 'processed_data' folder.\n"
     ]
    }
   ],
   "source": [
    "# Create the 'processed_data' folder if it doesn't exist\n",
    "if not os.path.exists('processed_data'):\n",
    "    os.makedirs('processed_data')\n",
    "\n",
    "# Loop through the list of DataFrames and save them as CSV files\n",
    "for i, df in enumerate(df_list, start=1):\n",
    "    file_name = f'df_{i}.csv'\n",
    "    file_path = os.path.join('processed_data', file_name)\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"DataFrames saved as CSV files in the 'processed_data' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
